% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_autoencoder.R
\name{run_autoencoder}
\alias{run_autoencoder}
\title{Run autoencoder}
\source{
\href{https://bradleyboehmke.github.io/HOML/autoencoders.html}{
autoencoder documentation}
}
\usage{
run_autoencoder(
  obj,
  transpose = TRUE,
  assay = NULL,
  slot = NULL,
  metadata = NULL,
  color_var = NULL,
  label_var = NULL,
  hidden = c(2),
  activation = "Tanh",
  sparse = FALSE,
  variable_importances = TRUE,
  epochs = 10,
  seed = 2020,
  ...
)
}
\arguments{
\item{obj}{Seurat object or matrix to run autoencoder on.}

\item{transpose}{Whether to transpose the matrix first.}

\item{assay}{Assay to use.}

\item{slot}{Data slot to use.}

\item{hidden}{Hidden layer sizes (e.g. [100, 100]). Defaults to c(200, 200).}

\item{activation}{Activation function. Must be one of: "Tanh", "TanhWithDropout", "Rectifier", "RectifierWithDropout", "Maxout",
"MaxoutWithDropout". Defaults to Rectifier.}

\item{sparse}{\code{Logical}. Sparse data handling (more efficient for data with lots of 0 values). Defaults to FALSE.}

\item{variable_importances}{\code{Logical}. Compute variable importances for input features (Gedeon method) - can be slow for large
networks. Defaults to TRUE.}

\item{epochs}{How many times the dataset should be iterated (streamed), can be fractional. Defaults to 10.}

\item{seed}{Seed passed to \[base]{set.seed} 
for reproducibility between runs.}

\item{...}{Additional parameters passed to \link[h2o]{h2o.deeplearning}.}
}
\value{
List containing:
\itemize{
\item{embedding : }{Latent space embedding from the smallest hidden layer.}
\item{model : }{Trained autoencoder model with parameters.}
\item{variable_importance : }{Feature importance data from
 \link[h2o]{h2o.varimp} in \pkg{data.table} format.}
\item{plot_latent : }{2D plot of the embedding. 
\emph{Note}: Only uses nodes 1 and 2, 
even when the embedding has more dimensions.}
\item{plot_importance : }{Feature importance plot from
 \link[h2o]{h2o.varimp_plot}.}
}
}
\description{
Run a customisable deep autoencoder to reduce your data to N dimensions,
and extract feature importance scores.
}
\details{
Uses \link[h2o]{h2o.deeplearning}.
}
\examples{
#### Import data ####
obj <- phenomix::get_HPO()
#### Subset the data to speed up example ####
obj <- obj[obj@assays$RNA@var.features[1:300], ]
#### Train autoencoder ####
ae_res <- phenomix::run_autoencoder(obj = obj, 
                                    color_var = "group_depth3")
}
